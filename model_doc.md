# Документация по обучению модели классификации цветов

## Обзор проекта

Данная документация описывает процесс обучения модели глубокого обучения для классификации изображений цветов на основе датасета Flowers102. Модель построена на базе архитектуры EfficientNet-V2-S с применением техник аугментации данных и transfer learning.

## Архитектура модели

### Базовая модель
- **Архитектура**: EfficientNet-V2-S
- **Предобученные веса**: ImageNet ('DEFAULT')
- **Модификации**: Замена последнего слоя классификатора

```python
model = efficientnet_v2_s(weights='DEFAULT')
model.classifier[1] = nn.Linear(in_features=1280, out_features=102, bias=True)
```

### Параметры модели
- **Входные признаки классификатора**: 1280
- **Выходные классы**: 102 (количество видов цветов в Flowers102)
- **Устройство**: CUDA (GPU)

## Датасет и предобработка

### Датасет Flowers102
- **Источник**: Oxford Flowers102
- **Количество классов**: 102
- **Разделение**: train/validation/test

### Класс FlowersDataset

```python
class FlowersDataset(Dataset):
    def __init__(self, root, split, processor, do_augments=False):
        self.do_augments = do_augments
        self.dataset = Flowers102(root=root, split=split)
        self.augments = T.Compose([...])
        self.transforms = processor
```

#### Параметры инициализации:
- `root`: Путь к корневой директории датасета
- `split`: Разделение данных ('train', 'val', 'test')
- `processor`: Препроцессор изображений
- `do_augments`: Флаг применения аугментации (по умолчанию False)

## Аугментация данных

### Применяемые техники аугментации

```python
self.augments = T.Compose([
    T.RandomHorizontalFlip(),                    # Случайный горизонтальный поворот
    T2.RandomResize(min_size=128, max_size=512), # Случайное изменение размера
    T.RandomVerticalFlip(),                      # Случайный вертикальный поворот
    T.RandomRotation(degrees=(-80, 80)),         # Случайный поворот ±80°
    T.RandomPerspective(),                       # Случайная перспектива
    T.RandomApply([T2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.))], p=0.5)  # Размытие по Гауссу (50% вероятность)
])
```

### Цель аугментации
- Увеличение разнообразия тренировочных данных
- Повышение устойчивости модели к различным трансформациям
- Предотвращение переобучения

## Предобработка изображений

### Стандартная предобработка

```python
preprocessor = T.Compose([
    T.ToTensor(),                                          # Преобразование в тензор
    T.CenterCrop(size=[384]),                             # Центральное обрезание до 384x384
    T.Normalize(mean=[0.485, 0.456, 0.406],               # Нормализация по ImageNet
                std=[0.229, 0.224, 0.225])
])
```

### Параметры нормализации
- **Mean**: [0.485, 0.456, 0.406] - средние значения RGB каналов ImageNet
- **Std**: [0.229, 0.224, 0.225] - стандартные отклонения RGB каналов ImageNet

## Функции обучения и валидации

### Функция обучения

```python
def train(model, optimizer, loss_func, loader, epoch):
    model.train()
    # Итерация по батчам
    # Вычисление градиентов
    # Обновление весов
    # Логирование точности каждые 10 итераций
```

#### Основные операции:
1. Установка модели в режим обучения
2. Обнуление градиентов оптимизатора
3. Прямой проход (forward pass)
4. Вычисление функции потерь
5. Обратное распространение ошибки
6. Обновление параметров модели
7. Вычисление и вывод точности

### Функция валидации

```python
@torch.inference_mode()
def valid(model, loader, epoch):
    model.eval()
    # Оценка модели без вычисления градиентов
    # Расчет средней точности
```

#### Основные операции:
1. Установка модели в режим оценки
2. Отключение вычисления градиентов
3. Прямой проход по валидационным данным
4. Вычисление средней точности

## Результаты обучения

### Прогресс по эпохам

| Эпоха | Точность валидации | Примечания |
|-------|-------------------|------------|
| 0 | 46.0% | Начальная эпоха, низкая точность |
| 1 | 71.5% | Значительное улучшение |
| 2 | 87.2% | Быстрый рост точности |
| 3 | 89.7% | Стабилизация роста |
| 4 | 92.7% | Продолжение улучшения |
| 5 | 93.6% | Медленный рост |
| 6 | 94.0% | Приближение к насыщению |
| 7 | 94.4% | Минимальное улучшение |
| 8 | 94.0% | Стабилизация |

### Анализ результатов

#### Положительные тенденции:
- **Быстрая сходимость**: Значительное улучшение в первые эпохи
- **Высокая итоговая точность**: >94% на валидационной выборке
- **Стабильное обучение**: Отсутствие резких колебаний

#### Наблюдения:
- **Transfer Learning эффективность**: Использование предобученных весов ImageNet обеспечило быстрый старт
- **Переобучение на тренировочных данных**: К 3-й эпохе точность на тренировочных батчах достигла 100%
- **Плато валидации**: После 6-й эпохи точность валидации стабилизировалась

## Технические детали

### Гиперпараметры
- **Размер изображения**: 384x384 пикселей
- **Batch size**: 16 (предположительно, исходя из логов)
- **Количество эпох**: 30 (запланировано, прервано на 9-й)
- **Устройство**: CUDA GPU

### Метрики производительности
- **Скорость обучения**: ~2 итерации/секунду
- **Скорость валидации**: ~4.5 итерации/секунду
- **Время на эпоху**: ~30-35 секунд обучение + ~13-15 секунд валидация

### Функция потерь
# Документация по обучению модели классификации цветов (продолжение)

### Функция потерь
- **Тип**: Cross-Entropy Loss (стандартная для многоклассовой классификации)
- **Применение**: Сравнение предсказанных вероятностей с истинными метками классов

### Оптимизатор
- **Тип**: Не указан в коде, но рекомендуется Adam или AdamW
- **Параметры**: Настройки learning rate и weight decay зависят от конкретной реализации

## Архитектурные особенности EfficientNet-V2-S

### Преимущества выбранной архитектуры
- **Эффективность**: Оптимальное соотношение точности к вычислительным затратам
- **Масштабируемость**: Возможность адаптации под различные размеры входных данных
- **Современность**: Улучшенная версия EfficientNet с оптимизированными блоками

### Модификация классификатора
```python
# Исходный классификатор EfficientNet-V2-S рассчитан на 1000 классов ImageNet
# Замена на 102 класса для Flowers102
model.classifier[1] = nn.Linear(in_features=1280, out_features=102, bias=True)
```

## Стратегия обучения

### Transfer Learning подход
1. **Предобученная модель**: Загрузка весов, обученных на ImageNet
2. **Feature extraction**: Использование предобученных признаков
3. **Fine-tuning**: Дообучение всей модели на целевом датасете

### Этапы обучения
1. **Инициализация**: Загрузка предобученной модели
2. **Модификация**: Замена последнего слоя
3. **Обучение**: Итеративная оптимизация параметров
4. **Валидация**: Оценка качества на отложенной выборке

## Анализ динамики обучения

### График точности по эпохам

```
Валидационная точность:
Эпоха 0: ████████████████████████▍░░░░░░░░░░░░░░░░░░░░░░░░░ 46.0%
Эпоха 1: █████████████████████████████████████▊░░░░░░░░░░░░ 71.5%
Эпоха 2: ███████████████████████████████████████████████▊░░ 87.2%
Эпоха 3: ████████████████████████████████████████████████▉░ 89.7%
Эпоха 4: ██████████████████████████████████████████████████ 92.7%
Эпоха 5: ██████████████████████████████████████████████████ 93.6%
Эпоха 6: ██████████████████████████████████████████████████ 94.0%
Эпоха 7: ██████████████████████████████████████████████████ 94.4%
Эпоха 8: ██████████████████████████████████████████████████ 94.0%
```

### Интерпретация результатов

#### Фаза быстрого роста (Эпохи 0-2)
- **Характеристика**: Резкий рост точности с 46% до 87.2%
- **Причина**: Адаптация предобученных признаков к новой задаче
- **Значение**: Эффективность transfer learning

#### Фаза медленного улучшения (Эпохи 3-5)
- **Характеристика**: Постепенный рост с 89.7% до 93.6%
- **Причина**: Тонкая настройка весов модели
- **Значение**: Приближение к оптимуму

#### Фаза стабилизации (Эпохи 6-8)
- **Характеристика**: Точность колеблется в районе 94%
- **Причина**: Достижение предела обобщающей способности
- **Значение**: Возможное начало переобучения

## Проблемы и решения

### Выявленные проблемы

#### 1. Переобучение на тренировочных данных
**Симптомы**:
- Точность на тренировочных батчах достигает 100% к 3-й эпохе
- Точность валидации растет медленнее

**Возможные решения**:
```python
# Увеличение регуляризации
model = efficientnet_v2_s(weights='DEFAULT')
# Добавление Dropout
model.classifier = nn.Sequential(
    nn.Dropout(p=0.3),
    nn.Linear(1280, 102)
)

# Уменьшение learning rate
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)
```

#### 2. Стабилизация точности валидации
**Симптомы**:
- Точность валидации перестает расти после 6-й эпохи

**Возможные решения**:
- Реализация early stopping
- Уменьшение learning rate по расписанию
- Увеличение аугментации данных

### Рекомендации по улучшению

#### 1. Настройка гиперпараметров
```python
# Learning Rate Scheduler
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='max', factor=0.5, patience=3, verbose=True
)

# Early Stopping
class EarlyStopping:
    def __init__(self, patience=7, min_delta=0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None
```

#### 2. Расширенная аугментация
```python
# Дополнительные техники аугментации
additional_augments = T.Compose([
    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    T.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    T.RandomErasing(p=0.3, scale=(0.02, 0.33), ratio=(0.3, 3.3))
])
```

#### 3. Ансамблирование моделей
```python
# Комбинирование различных архитектур
models = [
    efficientnet_v2_s(),
    efficientnet_v2_m(),
    resnet50()
]
# Усреднение предсказаний
```

## Валидация и тестирование

### Метрики качества

#### Основная метрика
- **Accuracy**: Доля правильных предсказаний
- **Формула**: `(TP + TN) / (TP + TN + FP + FN)`
- **Текущий результат**: 94.4% (лучший результат)

#### Дополнительные метрики (рекомендуемые)
```python
from sklearn.metrics import classification_report, confusion_matrix

# Precision, Recall, F1-score для каждого класса
def detailed_evaluation(model, loader):
    y_true, y_pred = [], []
    
    with torch.no_grad():
        for images, labels in loader:
            outputs = model(images.to(device))
            predictions = outputs.