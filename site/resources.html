<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ресурсы | Система захвата жестов</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>Система захвата жестов</h1>
            <nav>
                <ul>
                    <li><a href="index.html">Главная</a></li>
                    <li><a href="about.html">О проекте</a></li>
                    <li><a href="participants.html">Участники</a></li>
                    <li><a href="journal.html">Журнал</a></li>
                    <li><a href="resources.html" class="active">Ресурсы</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main>
        <section class="page-content">
            <div class="container">
                <h2>Полезные ресурсы</h2>
                
                <div class="resources-intro">
                    <p>В этом разделе собраны полезные материалы и источники, которые помогают нам 
                    в разработке системы захвата жестов. Они могут быть интересны как для участников проекта, 
                    так и для всех, кто интересуется компьютерным зрением и распознаванием жестов.</p>
                </div>
                
                <div class="resources-categories">
                    <div class="resources-category">
                        <h3>Организации-партнеры</h3>
                        <ul class="resources-list">
                            <li class="resource-item">
                                <h4><a href="https://www.university.edu" target="_blank">Университетская лаборатория компьютерного зрения</a></h4>
                                <p>Наш основной партнер, предоставляющий доступ к исследовательскому оборудованию и экспертизе.</p>
                            </li>
                            <li class="resource-item">
                                <h4><a href="https://www.techcompany.com" target="_blank">Tech Company Inc.</a></h4>
                                <p>Коммерческий партнер, заинтересованный во внедрении технологии распознавания жестов в свои продукты.</p>
                            </li>
                        </ul>
                    </div>
                    
                    <div class="resources-category">
                        <h3>Библиотеки и инструменты</h3>
                        <ul class="resources-list">
                            <li class="resource-item">
                                <h4><a href="https://mediapipe.dev" target="_blank">MediaPipe</a></h4>
                                <p>Библиотека от Google, которая предоставляет готовые решения для отслеживания рук, лиц и тела.</p>
                            </li>
                            <li class="resource-item">
                                <h4><a href="https://opencv.org" target="_blank">OpenCV</a></h4>
                                <p>Библиотека компьютерного зрения с открытым исходным кодом, предоставляющая множество алгоритмов обработки изображений.</p>
                            </li>
                            <li class="resource-item">
                                <h4><a href="https://www.tensorflow.org" target="_blank">TensorFlow</a></h4>
                                <p>Библиотека машинного обучения от Google, используемая для создания и обучения моделей распознавания жестов.</p>
                            </li>
                            <li class="resource-item">
                                <h4><a href="https://pytorch.org" target="_blank">PyTorch</a></h4>
                                <p>Гибкая библиотека глубокого обучения, используемая исследовательским сообществом для экспериментов.</p>
                            </li>
                        </ul>
                    </div>
                    
                    <div class="resources-category">
                        <h3>Научные статьи и публикации</h3>
                        <ul class="resources-list">
                            <li class="resource-item">
                                <h4><a href="https://arxiv.org/abs/2006.10214" target="_blank">MediaPipe Hands: On-device Real-time Hand Tracking</a></h4>
                                <p>Статья, описывающая алгоритмы, используемые в MediaPipe для отслеживания рук.</p>
                            </li>
                            <li class="resource-item">
                                <h4><a href="https://arxiv.org/abs/1804.08170" target="_blank">Hand Pose Estimation: A Survey</a></h4>
                                <p>Обзорная статья, описывающая современные подходы к оценке положения рук.</p>
                            </li>
                            <li class="resource-item">
                                <h4><a href="https://arxiv.org/abs/2103.02708" target="_blank">Dynamic Hand Gesture Recognition Using Neural Networks</a></h4>
                                <p>Исследование методов распознавания динамических жестов с использованием нейронных сетей.</p>
                            </li>
                        </ul>
                    </div>
                    
                    <div class="resources-category">
                        <h3>Обучающие материалы</h3>
                        <ul class="resources-list">
                            <li class="resource-item">
                                <h4><a href="https://www.coursera.org/learn/computer-vision" target="_blank">Курс "Компьютерное зрение" на Coursera</a></h4>
                                <p>Базовый курс по компьютерному зрению, охватывающий основные алгоритмы и подходы.</p>
                            </li>
                            <li class="resource-item">
                                <h4><a href="https://www.youtube.com/watch?v=01sAkU_NvOY" target="_blank">Туториал по MediaPipe Hands на YouTube</a></h4>
                                <p>Подробный видеоурок по настройке и использованию MediaPipe для отслеживания рук.</p>
                                <div class="resource-preview">
                                    <iframe width="560" height="315" src="https://www.youtube.com/embed/01sAkU_NvOY" frameborder="0" allowfullscreen></iframe>
                                </div>
                            </li>
                            <li class="resource-item">
                                <h4><a href="https://github.com/google/mediapipe/blob/master/docs/solutions/hands.md" target="_blank">Документация MediaPipe Hands</a></h4>
                                <p>Официальная документация с примерами кода и объяснением функциональности.</p>
                            </li>
                        </ul>
                    </div>
                    
                    <div class="resources-category">
                        <h3>Наборы данных</h3>
                        <ul class="resources-list">
                            <li class="resource-item">
                                <h4><a href="https://www.kaggle.com/datasets/gti-upm/leapgestrecog" target="_blank">Leap Motion Gesture Recognition Dataset</a></h4>
                                <p>Набор данных жестов, записанных с использованием контроллера Leap Motion.</p>
                            </li>
                            <li class="resource-item">
                                <h4><a href="https://www.kaggle.com/datasets/kapitanov/hagrid" target="_blank">HAGRID - HAnd Gesture Recognition Image Dataset</a></h4>
                                <p>Большой набор изображений для распознавания жестов рук с более чем 550000 аннотированных изображений.</p>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2024 Проектная деятельность. Все права защищены.</p>
        </div>
    </footer>
</body>
</html> 